---
title: "Faculty Classification"
author: Chad Evans
output: 
  github_document:
  toc: true
always_allow_html: yes
params:
 d: !r Sys.Date() 

---
Built with R version `r getRversion()`.  Last run on `r params$d`.

* [Configure](#configure)
    + Libraries
    + directories
    + data
* [Munge](#munge)
* [Exploratory Analysis](#exploratory-analysis)
    + [Missing Data](#missing)
* [Single Imputation](#impute)
* [Cluster Analysis](#cluster)
    + [K-means Clustering Algorithm](#kmeans)
    + [Tabulations](#tables)

## Configure
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, fig.width=7, fig.height=7, fig.path='graphs/', cache.path ='cache/')
```

```{r Libraries, include=FALSE, eval=TRUE, echo=TRUE, warning=TRUE,error=FALSE, message=TRUE, tidy=TRUE, results='markup', cache=FALSE, fig.width=7, fig.height=7}
library(tidyverse)
library(stats)
library(mice)
library(knitr)
```

```{r Directories, include=FALSE}
Private_Cache <- "/Users/chadgevans/Research/Projects/Data/HERI/Cache"
Raw<-"/Users/chadgevans/Research/Projects/Data/HERI/Raw"
Munge<-"./munge"
Source<-"./src"
Graph<-"./graphs"
```

```{r Data, eval=FALSE}
source(file.path(Munge, "01_Merge_the_data.R"))
source(file.path(Munge, "02_Clean_the_data.R"))
source(file.path(Munge, "Recode_HERI.R"))
save(df, file=file.path(Private_Cache,"HERI_Class.RData"))
```

## Munge
```{r Clean Data Import}
load(file.path(Private_Cache,"HERI_Class.RData"))
```


We will perform cluster analysis on all variables relating to job attitudes, work activities and experiences.  Let's identify all the variables in our data that do not reach this criteria and remove them from the data.  Also, many variables in these data only pertain to part-time faculty.  So many faculty do not have responses to these part-time faculty questions.  Those variables were removed from the first cluster analysis

```{r Variable_groupings}
SVYVARS<-c("ACE","SUBJID","YEAR","ACERECODE","RESTYPE")
INSTVARS<-c("DEPTA","INSTTYPE","INSTCONT","SELECTIVITY","CARNEGIE")
DEMGVARS<-c("GENACT03","GENACT04","NCHILD1","NCHILD2","MARITAL","SEX","NATENGSP","RACEGROUP","STATE","OBEREG","MAJORA","AGE")
PTVARS<-c("PTCHOICE","PTWORKFT","PTTSEEK","PTCAREER","PTREASON01","PTREASON02","PTREASON03","PTREASON04","PTREASON05","PTREASON06","PTREASON07","PTRESOURCES01","PTRESOURCES02","PTRESOURCES03","PTRESOURCES04","PTRESOURCES05","PTOPN01","PTOPN02","PTOPN03","PTOPN04","PTOPN05","PTOPN06","PTOPN07","PTOPN08","PTOPN09","PTOPN10","PTTEACH","PTSALARY","PTPAY")
OTHERS<-c("DEPTDISC","SALARY","TENUREYR","SALARY12","CCRANK","CCSTATUS","SALARYBASE","BIRTHYR")

OMIT<-c(SVYVARS,INSTVARS,DEMGVARS,PTVARS,OTHERS)
```

```{r data_subsets, eval=FALSE}
df<-df %>% select(-one_of(OMIT)) 

lwdata<-df %>% na.omit()
save(lwdata, file=file.path(Private_Cache,"lwdata.RData"))

tempData<-df %>% 
  mice(m=1,maxit=50,meth='pmm',seed=500)
save(tempData, file=file.path(Private_Cache,"tempData.RData"))
IData <- complete(tempData,1)
save(IData, file=file.path(Private_Cache,"IData.RData"))
```


## Exploratory Analysis

### Missing Data{#missing}

```{r}
miss_pct<-df %>% 
  map_dbl(function(x) { round((sum(is.na(x)) / length(x)) * 100, 1) })
data.frame(miss=miss_pct, var=names(miss_pct), row.names=NULL) %>%
ggplot(aes(x=reorder(var, -miss), y=miss)) +
geom_bar(stat='identity', fill='red') +
labs(x='', y='% missing', title='Percent missing data by feature') +
theme(axis.text.x=element_text(angle=90, hjust=1))
```

The missingness in these data is very low.  About 20 variables have 3-10 percent missing.  The vast majority have trivial amounts of missingness.  When applying listwise deletion, `r 100*(nrow(df)-nrow(na.omit(df)))/ nrow(df)` percent of observations are lot.  This is because there are so many covariates and the missingness really adds up.  It is still worth considering listwise deletion.  We'll compare the results with a dataset that has been singly imputated, in order to capitalize on all available information.  Single imputation is less concerning here because we are not interested in standard errors.  We just are trying to induce a classification schema.  

## Analysis
```{r reload_data}
load(file.path(Private_Cache,"IData.RData"))
load(file.path(Private_Cache,"lwdata.RData"))
data<-lwdata #IData

```

## Determine the number of Clusters.
I used the "elbow method"

```{r Create_Binaries}
dfClust<-data.frame(model.matrix(~ ., data=data))
```


```{r Determin_Number_Clusters}
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}
wssplot(dfClust, nc=7) # put in # of clusters here
```

## Cluster Analysis{#cluster}
Five clusters appears to be the best fit, according to the elbow method.

```{r K_means_procedure}
Clust<- dfClust %>%
  kmeans(5, nstart = 20)
```

```{r add_clusters}
CLUSTER<-Clust$cluster
df<-cbind(df,CLUSTER)
```

```{r demography_table}
options(digits=2)
list<-do.call(rbind, sapply(df[DEMGVARS], function(x){
    if(is.numeric(x)==TRUE){
      means<-aggregate(x ~ df$CLUSTER, FUN=mean, na.action=na.omit)
      print(means)[,2]
      }
    else{
      prop.table(table(x, df$CLUSTER),2)
      }
  }))
kable(list, caption = "Distribution of Adjunct Types by Demographic Characteristics")
```

```{r Institution_table}
list<-do.call(rbind, sapply(df3[INSTVARS], function(x){
    if(is.numeric(x)==TRUE){
      means<-aggregate(x ~ df$CLUSTER, FUN=mean, na.action=na.omit)
      print(means)[,2]
      }
    else{
      prop.table(table(x, df$CLUSTER),2)
      }
  }))
kable(list, caption = "Distribution of Adjunct Types by Institutional Characteristics")
```


